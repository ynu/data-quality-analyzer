# 数据质量维度分析程序

这是一个用于分析数据库字段数据质量维度的自动化工具。程序从CSV文件中读取表结构信息，调用**HiAgent智能体平台**的API对每个字段进行数据质量维度分析，并将分析结果保存到输出文件中。

> **注意**：本程序所有代码由Costrict自动生成

## 功能特点

1. **数据质量维度分析**：对每个字段分析其应满足的完整性、一致性、正确性、准确性、唯一性、及时性等维度
2. **批量处理**：支持批量处理大量数据，可配置批次大小
3. **断点续传**：支持处理中断后继续，避免重复处理已成功的数据
4. **错误处理**：自动记录处理失败的数据，便于后续重试
5. **实时保存**：每处理成功一行数据立即保存，确保数据不丢失
6. **详细日志**：提供详细的处理日志，便于调试和监控

## 工作流程

1. 读取输入CSV文件中的表结构信息
2. 为每个字段创建独立的API会话
3. 调用智能体API进行数据质量维度分析
4. 解析API返回的JSON格式结果
5. 将分析结果实时保存到输出文件
6. 记录处理失败的数据到单独文件

## 安装依赖

```bash
npm install
```

## 配置

### 方法一：使用配置文件（推荐）

1. 复制配置文件模板：
```bash
cp config.example.js config.js
```

2. 编辑 `config.js` 文件，填入实际的配置值：

```javascript
const CONFIG = {
  // 必填：请替换为实际的API密钥（用于HTTP请求头认证）
  API_KEY: 'your_actual_api_key_here',
  
  // 应用标识（请求体中使用，值应与API_KEY相同）
  APP_KEY: 'your_actual_api_key_here',
  
  // API基础URL，通常不需要修改
  API_BASE_URL: 'https://agent.ynu.edu.cn/api/proxy/api/v1',
  
  // 输入文件路径
  INPUT_FILE: 'input.csv',
  
  // 输出文件路径
  OUTPUT_FILE: 'output.csv',
  
  // API调用间隔时间（毫秒），避免过于频繁的请求
  API_DELAY: 1000,
  
  // 每次处理的最大行数，避免一次性处理过多数据
  MAX_ROWS_PER_BATCH: 100,
  
  // 是否启用详细日志
  VERBOSE_LOGGING: true,
  
  // 用户ID（用于API请求中的UserID字段）
  // 可以使用占位符 {index} 会在处理时替换为当前行号
  USER_ID: 'user_{index}',
  
  // 查询文本（用于API请求中的Query字段）
  // 可以使用占位符 {fieldName} 和 {tableName} 会在处理时替换为当前字段名和表名
  QUERY: '你的查询文本...'
};
```

### 方法二：直接修改代码

如果不使用配置文件，可以直接修改 `index.js` 文件中的默认配置。

## 使用方法

1. 准备输入文件 `input.csv`，确保格式正确
2. 配置API密钥和其他参数
3. 运行程序：

```bash
npm start
```

或者

```bash
node index.js
```

## 输入文件格式

input.csv文件应包含以下字段：
- 字段名称：要分析的字段名
- 所属表：字段所属的表名
- 其他字段（程序会忽略，但会保留在成功记录中）

示例：
```
字段名称,所属表,名称,类型,长度,主键,责任部门,质量检查规则,类别,所属类别
单位编码,院系所单位信息,DWBM,STRING,100 ,是,党政办公室（党委巡察办）,主键必须唯一,,学校基本数据类
单位名称,院系所单位信息,DWMC,STRING,500 ,否,党政办公室（党委巡察办）,名称不为空,,学校基本数据类
```

## 输出文件格式

output.csv文件将包含以下字段：
- table_name：表名
- field_name：字段名
- 维度：数据质量维度（完整性、一致性、正确性、准确性、唯一性、及时性）
- 备注：对该维度要求的详细说明

示例：
```
table_name,field_name,维度,备注
院系所单位信息,单位编码,唯一性,单位编码应唯一标识一个院系所单位，确保不重复
院系所单位信息,单位编码,正确性,单位编码的格式、值域应符合预定义规则
院系所单位信息,单位名称,完整性,单位名称为识别院系所单位的基本信息，业务操作需完备存在
```

## 其他输出文件

程序运行过程中会生成以下辅助文件：

1. **success_input.csv**：记录已成功处理的原始数据，用于断点续传
2. **failed_input.csv**：记录处理失败的数据及失败原因，便于后续重试

## 配置参数说明

- `API_KEY`/`APP_KEY`：智能体API的认证密钥，必填
- `API_BASE_URL`：API服务地址，通常不需要修改
- `INPUT_FILE`：输入文件路径，默认为 'input.csv'
- `OUTPUT_FILE`：输出文件路径，默认为 'output.csv'
- `API_DELAY`：API调用间隔时间（毫秒），默认1000ms
- `MAX_ROWS_PER_BATCH`：每批处理的最大行数，默认100
- `VERBOSE_LOGGING`：是否启用详细日志，默认true
- `USER_ID`：API请求中的用户ID，支持{index}占位符
- `QUERY`：发送给智能体的查询文本，支持{fieldName}和{tableName}占位符

## 注意事项

1. **API密钥安全**：请妥善保管API密钥，不要提交到版本控制系统
2. **网络连接**：确保网络连接正常，能够访问智能体API服务
3. **处理中断**：如果处理过程中断，重新运行程序会自动跳过已成功处理的数据
4. **资源占用**：处理大量数据时会占用一定的网络和计算资源
5. **API限制**：注意API服务的调用频率限制，适当调整API_DELAY参数

## 错误处理

程序包含完善的错误处理机制：

- **网络错误**：自动重试和错误记录
- **API错误**：详细的错误信息和建议
- **数据格式错误**：跳过无效数据并记录
- **文件操作错误**：检查文件存在性和权限

常见错误及解决方案：

1. **404错误**：检查API端点路径是否正确，智能体是否已发布
2. **401/403错误**：检查API密钥是否有效和权限是否足够
3. **500错误**：检查请求格式是否正确，联系API服务提供方

## 依赖包

- `csv-parser`：用于读取CSV文件
- `csv-writer`：用于写入CSV文件
- `axios`：用于HTTP请求